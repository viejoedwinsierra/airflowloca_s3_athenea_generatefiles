amzn2extra-docker                                                                                                                                                                                   | 2.9 kB  00:00:00     
(1/5): amzn2-core/2/x86_64/group_gz                                                                                                                                                                 | 2.7 kB  00:00:00     
(2/5): amzn2-core/2/x86_64/updateinfo                                                                                                                                                               | 1.2 MB  00:00:00     
(3/5): amzn2extra-docker/2/x86_64/updateinfo                                                                                                                                                        |  31 kB  00:00:00     
(4/5): amzn2extra-docker/2/x86_64/primary_db                                                                                                                                                        | 156 kB  00:00:00     
(5/5): amzn2-core/2/x86_64/primary_db                                                                                                                                                               |  83 MB  00:00:01     
Resolving Dependencies
--> Running transaction check
---> Package docker.x86_64 0:25.0.14-1.amzn2.0.2 will be installed
--> Processing Dependency: containerd >= 1.3.2 for package: docker-25.0.14-1.amzn2.0.2.x86_64
--> Processing Dependency: libcgroup >= 0.40.rc1-5.15 for package: docker-25.0.14-1.amzn2.0.2.x86_64
--> Processing Dependency: runc >= 1.0.0 for package: docker-25.0.14-1.amzn2.0.2.x86_64
--> Processing Dependency: pigz for package: docker-25.0.14-1.amzn2.0.2.x86_64
--> Running transaction check
---> Package containerd.x86_64 0:2.1.5-1.amzn2.0.5 will be installed
---> Package libcgroup.x86_64 0:0.41-21.amzn2 will be installed
---> Package pigz.x86_64 0:2.3.4-1.amzn2.0.1 will be installed
---> Package runc.x86_64 0:1.3.4-2.amzn2 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

===========================================================================================================================================================================================================================
 Package                                           Arch                                          Version                                                    Repository                                                Size
===========================================================================================================================================================================================================================
Installing:
 docker                                            x86_64                                        25.0.14-1.amzn2.0.2                                        amzn2extra-docker                                         46 M
Installing for dependencies:
 containerd                                        x86_64                                        2.1.5-1.amzn2.0.5                                          amzn2extra-docker                                         20 M
 libcgroup                                         x86_64                                        0.41-21.amzn2                                              amzn2-core                                                66 k
 pigz                                              x86_64                                        2.3.4-1.amzn2.0.1                                          amzn2-core                                                81 k
 runc                                              x86_64                                        1.3.4-2.amzn2                                              amzn2extra-docker                                        3.9 M

Transaction Summary
===========================================================================================================================================================================================================================
Install  1 Package (+4 Dependent packages)

Total download size: 71 M
Installed size: 261 M
Downloading packages:
(1/5): libcgroup-0.41-21.amzn2.x86_64.rpm                                                                                                                                                           |  66 kB  00:00:00     
(2/5): pigz-2.3.4-1.amzn2.0.1.x86_64.rpm                                                                                                                                                            |  81 kB  00:00:00     
(3/5): containerd-2.1.5-1.amzn2.0.5.x86_64.rpm                                                                                                                                                      |  20 MB  00:00:00     
(4/5): runc-1.3.4-2.amzn2.x86_64.rpm                                                                                                                                                                | 3.9 MB  00:00:00     
(5/5): docker-25.0.14-1.amzn2.0.2.x86_64.rpm                                                                                                                                                        |  46 MB  00:00:00     
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total                                                                                                                                                                                       99 MB/s |  71 MB  00:00:00     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : runc-1.3.4-2.amzn2.x86_64                                                                                                                                                                               1/5 
  Installing : containerd-2.1.5-1.amzn2.0.5.x86_64                                                                                                                                                                     2/5 
  Installing : libcgroup-0.41-21.amzn2.x86_64                                                                                                                                                                          3/5 
  Installing : pigz-2.3.4-1.amzn2.0.1.x86_64                                                                                                                                                                           4/5 
  Installing : docker-25.0.14-1.amzn2.0.2.x86_64                                                                                                                                                                       5/5 
  Verifying  : pigz-2.3.4-1.amzn2.0.1.x86_64                                                                                                                                                                           1/5 
  Verifying  : runc-1.3.4-2.amzn2.x86_64                                                                                                                                                                               2/5 
  Verifying  : docker-25.0.14-1.amzn2.0.2.x86_64                                                                                                                                                                       3/5 
  Verifying  : containerd-2.1.5-1.amzn2.0.5.x86_64                                                                                                                                                                     4/5 
  Verifying  : libcgroup-0.41-21.amzn2.x86_64                                                                                                                                                                          5/5 

Installed:
  docker.x86_64 0:25.0.14-1.amzn2.0.2                                                                                                                                                                                      

Dependency Installed:
  containerd.x86_64 0:2.1.5-1.amzn2.0.5                      libcgroup.x86_64 0:0.41-21.amzn2                      pigz.x86_64 0:2.3.4-1.amzn2.0.1                      runc.x86_64 0:1.3.4-2.amzn2                     

Complete!
  2  httpd_modules            available    [ =1.0  =stable ]
  3  memcached1.5             available    \
        [ =1.5.1  =1.5.16  =1.5.17 ]
  9  R3.4                     available    [ =3.4.3  =stable ]
 18  libreoffice              available    \
        [ =5.0.6.2_15  =5.3.6.1  =stable ]
 19  gimp                     available    [ =2.8.22 ]
 20  docker=latest            enabled      \
        [ =17.12.1  =18.03.1  =18.06.1  =18.09.9  =stable ]
 21  mate-desktop1.x          available    \
        [ =1.19.0  =1.20.0  =stable ]
 22  GraphicsMagick1.3        available    \
        [ =1.3.29  =1.3.32  =1.3.34  =stable ]
 25  testing                  available    [ =1.0  =stable ]
 26  ecs                      available    [ =stable ]
 27  corretto8                available    \
        [ =1.8.0_192  =1.8.0_202  =1.8.0_212  =1.8.0_222  =1.8.0_232
          =1.8.0_242  =stable ]
 32  lustre2.10               available    \
        [ =2.10.5  =2.10.8  =stable ]
 34  lynis                    available    [ =stable ]
 36  BCC                      available    [ =0.x  =stable ]
 37  mono                     available    [ =5.x  =stable ]
 38  nginx1                   available    [ =stable ]
 40  mock                     available    [ =stable ]
 43  livepatch                available    [ =stable ]
 45  haproxy2                 available    [ =stable ]
 46  collectd                 available    [ =stable ]
 47  aws-nitro-enclaves-cli   available    [ =stable ]
 48  R4                       available    [ =stable ]
 49  kernel-5.4               available    [ =stable ]
 50  selinux-ng               available    [ =stable ]
 52  tomcat9                  available    [ =stable ]
 55  kernel-5.10              available    [ =stable ]
 56  redis6                   available    [ =stable ]
 60  mock2                    available    [ =stable ]
 62  kernel-5.15              available    [ =stable ]
 63  postgresql14             available    [ =stable ]
 64  firefox                  available    [ =stable ]
 65  lustre                   available    [ =stable ]
 67  awscli1                  available    [ =stable ]
 68  php8.2                   available    [ =stable ]
 69  dnsmasq                  available    [ =stable ]
 70  unbound1.17              available    [ =stable ]
 72  collectd-python3         available    [ =stable ]
sh-4.2$ sudo systemctl enable --now docker
Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.
sh-4.2$ docker --version || sudo docker --version
Docker version 25.0.14, build 0bab007
sh-4.2$ sudo curl -L "https://github.com/docker/compose/releases/download/v2.29.7/docker-compose-linux-x86_64" -o /usr/local/bin/docker-compose
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100 60.8M  100 60.8M    0     0   206M      0 --:--:-- --:--:-- --:--:--  409M
sh-4.2$ sudo chmod +x /usr/local/bin/docker-compose
sh-4.2$ docker-compose version
Docker Compose version v2.29.7
sh-4.2$ cd /home/ssm-user/airflow-docker
sh-4.2$ ./run_airflow_lite.sh
=========================================
Pre-check: Docker y Docker Compose
=========================================
Using: sudo docker-compose
Docker version 25.0.14, build 0bab007
sudo: docker-compose: command not found
sh-4.2$ ls -ltr
total 8
-rw-r--r-- 1 ssm-user ssm-user 2765 Feb 20 05:13 docker-compose.lite.yaml
-rwxr-xr-x 1 ssm-user ssm-user 3305 Feb 20 05:21 run_airflow_lite.sh
sh-4.2$ rm run_airflow_lite.sh 
sh-4.2$ cat > run_airflow_lite.sh <<'EOF'
> #!/bin/bash
> set -euo pipefail
> 
> PROJECT_DIR="${HOME}/airflow-docker"
> COMPOSE_FILE="${PROJECT_DIR}/docker-compose.lite.yaml"
> 
> cd "${PROJECT_DIR}"
> 
> echo "========================================="
> echo "Pre-check: Docker y Docker Compose"
> echo "========================================="
> 
> # Require docker
> if ! command -v docker >/dev/null 2>&1; then
>   echo "ERROR: docker no está instalado o no está en PATH"
>   echo "En Amazon Linux 2 instala con:"
>   echo "  sudo yum update -y"
>   echo "  sudo amazon-linux-extras install -y docker"
>   echo "  sudo systemctl enable --now docker"
>   exit 1
> fi
> 
> # Require docker-compose (binario)
> if ! command -v docker-compose >/dev/null 2>&1; then
>   echo "ERROR: docker-compose no está instalado o no está en PATH"
>   echo "Instala docker-compose v2 binario con:"
>   echo "  sudo curl -L \"https://github.com/docker/compose/releases/download/v2.29.7/docker-compose-linux-x86_64\" -o /usr/local/bin/docker-compose"
>   echo "  sudo chmod +x /usr/local/bin/docker-compose"
>   exit 1
> fi
> 
> # Decide whether to use sudo for docker-compose based on docker socket access
> if docker ps >/dev/null 2>&1; then
>   DC="docker-compose"
> else
>   DC="sudo docker-compose"
> fi
> 
> echo "Using: ${DC}"
> docker --version
> ${DC} version
> 
> if [ ! -f "${COMPOSE_FILE}" ]; then
>   echo "ERROR: No existe ${COMPOSE_FILE}"
>   exit 1
> fi
> 
> echo "========================================="
> echo "Validando docker-compose config"
> echo "========================================="
> ${DC} -f "${COMPOSE_FILE}" config >/dev/null
> echo "OK: compose config"
> 
> echo "========================================="
> echo "Creando estructura local (dags/logs/plugins)"
> echo "========================================="
> mkdir -p dags logs plugins logs/dag_processor_manager
> chmod -R 775 dags logs plugins
> 
> echo "========================================="
> echo "Inicializando Airflow (airflow-init)"
> echo "========================================="
> set +e
> ${DC} -f "${COMPOSE_FILE}" up airflow-init
> INIT_RC=$?
> set -e
> 
> if [ $INIT_RC -ne 0 ]; then
>   echo "ERROR: airflow-init falló. Mostrando logs:"
>   ${DC} -f "${COMPOSE_FILE}" logs --tail=200 airflow-init || true
>   exit $INIT_RC
> fi
> 
> echo "========================================="
> echo "Levantando servicios (up -d)"
> echo "========================================="
> ${DC} -f "${COMPOSE_FILE}" up -d
> 
> echo "========================================="
> echo "Estado de contenedores"
> echo "========================================="
> ${DC} -f "${COMPOSE_FILE}" ps
> 
> echo "========================================="
> echo "Validación local de UI"
> echo "========================================="
> curl -fsSI http://localhost:8080 >/dev/null && echo "OK: Airflow responde en localhost:8080" || echo "WARN: aún no responde, revisa logs"
> 
> echo
> echo "========================================="
> echo "Airflow LITE está corriendo"
> echo "========================================="
> echo "URL: http://<EC2_PUBLIC_IP>:8080"
> echo "Usuario: airflow"
> echo "Password: airflow"
> echo
> echo "Comandos útiles:"
> echo "  ${DC} -f ${COMPOSE_FILE} logs -f --tail=200 airflow-webserver"
> echo "  ${DC} -f ${COMPOSE_FILE} logs -f --tail=200 airflow-scheduler"
> echo "  ${DC} -f ${COMPOSE_FILE} logs -f --tail=200 postgres"
> echo "  ${DC} -f ${COMPOSE_FILE} down"
> echo "  ${DC} -f ${COMPOSE_FILE} down -v  # reset total"
> EOF
sh-4.2$ 
sh-4.2$ chmod +x run_airflow_lite.sh
sh-4.2$ ls -ltr
total 8
-rw-r--r-- 1 ssm-user ssm-user 2765 Feb 20 05:13 docker-compose.lite.yaml
-rwxr-xr-x 1 ssm-user ssm-user 3305 Feb 20 05:25 run_airflow_lite.sh
sh-4.2$ bash run_airflow_lite.sh
=========================================
Pre-check: Docker y Docker Compose
=========================================
Using: sudo docker-compose
Docker version 25.0.14, build 0bab007
sudo: docker-compose: command not found
sh-4.2$ sudo usermod -aG docker ssm-user
sh-4.2$ exit
exit


Exiting session with sessionId: user4797248=edwin.sierra-p@mail.escuelaing.edu.co-nds2k3naipyu9g33dzr63uc5fu.

practice $ aws ssm start-session --target i-079ec2fd29e780141

Starting session with SessionId: user4797248=edwin.sierra-p@mail.escuelaing.edu.co-l79jvug6tr8oxf2n9aevd5k72i
sh-4.2$ id
uid=1001(ssm-user) gid=1001(ssm-user) groups=1001(ssm-user),992(docker)
sh-4.2$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
sh-4.2$ docker-compose version
Docker Compose version v2.29.7
sh-4.2$ cd /home/ssm-user/airflow-docker
sh-4.2$ bash run_airflow_lite.sh
=========================================
Pre-check: Docker y Docker Compose
=========================================
Using: docker-compose
Docker version 25.0.14, build 0bab007
Docker Compose version v2.29.7
=========================================
Validando docker-compose config
=========================================
OK: compose config
=========================================
Creando estructura local (dags/logs/plugins)
=========================================
=========================================
Inicializando Airflow (airflow-init)
=========================================
[+] Running 37/2
 ✔ airflow-init Pulled                                                                                                                                                                                               32.5s 
 ✔ postgres Pulled                                                                                                                                                                                                   13.8s 
[+] Running 4/3
 ✔ Network airflow-docker_default              Created                                                                                                                                                                0.1s 
 ✔ Volume "airflow-docker_postgres-db-volume"  Created                                                                                                                                                                0.0s 
 ✔ Container airflow-postgres                  Created                                                                                                                                                                0.4s 
 ✔ Container airflow-init                      Created                                                                                                                                                                0.0s 
Attaching to airflow-init
airflow-init  | ....................
airflow-init  | ERROR! Maximum number of retries (20) reached.
airflow-init  | 
airflow-init  | Last check result:
airflow-init  | $ airflow db check
airflow-init  | Unable to load the config, contains a configuration error.
airflow-init  | Traceback (most recent call last):
airflow-init  |   File "/usr/local/lib/python3.12/pathlib.py", line 1311, in mkdir
airflow-init  |     os.mkdir(self, mode)
airflow-init  | FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/logs/scheduler/2026-02-20'
airflow-init  | 
airflow-init  | During handling of the above exception, another exception occurred:
airflow-init  | 
airflow-init  | Traceback (most recent call last):
airflow-init  |   File "/usr/local/lib/python3.12/logging/config.py", line 608, in configure
airflow-init  |     handler = self.configure_handler(handlers[name])
airflow-init  |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
airflow-init  |   File "/usr/local/lib/python3.12/logging/config.py", line 876, in configure_handler
airflow-init  |     result = factory(**kwargs)
airflow-init  |              ^^^^^^^^^^^^^^^^^
airflow-init  |   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/log/file_processor_handler.py", line 53, in __init__
airflow-init  |     Path(self._get_log_directory()).mkdir(parents=True, exist_ok=True)
airflow-init  |   File "/usr/local/lib/python3.12/pathlib.py", line 1315, in mkdir
airflow-init  |     self.parent.mkdir(parents=True, exist_ok=True)
airflow-init  |   File "/usr/local/lib/python3.12/pathlib.py", line 1311, in mkdir
airflow-init  |     os.mkdir(self, mode)
airflow-init  | PermissionError: [Errno 13] Permission denied: '/opt/airflow/logs/scheduler'
airflow-init  | 
airflow-init  | The above exception was the direct cause of the following exception:
airflow-init  | 
airflow-init  | Traceback (most recent call last):
airflow-init  |   File "/home/airflow/.local/bin/airflow", line 5, in <module>
airflow-init  |     from airflow.__main__ import main
airflow-init  |   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/__init__.py", line 74, in <module>
airflow-init  |     settings.initialize()
airflow-init  |   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py", line 785, in initialize
airflow-init  |     LOGGING_CLASS_PATH = configure_logging()
airflow-init  |                          ^^^^^^^^^^^^^^^^^^^
airflow-init  |   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/logging_config.py", line 74, in configure_logging
airflow-init  |     raise e
airflow-init  |   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/logging_config.py", line 69, in configure_logging
airflow-init  |     dictConfig(logging_config)
airflow-init  |   File "/usr/local/lib/python3.12/logging/config.py", line 942, in dictConfig
airflow-init  |     dictConfigClass(config).configure()
airflow-init  |   File "/usr/local/lib/python3.12/logging/config.py", line 615, in configure
airflow-init  |     raise ValueError('Unable to configure handler '
airflow-init  | ValueError: Unable to configure handler 'processor'
airflow-init  | 
airflow-init exited with code 1
=========================================
Levantando servicios (up -d)
=========================================
[+] Running 4/4
 ✔ Container airflow-postgres   Healthy                                                                                                                                                                               0.6s 
 ✔ Container airflow-init       Started                                                                                                                                                                               1.6s 
 ✔ Container airflow-webserver  Started                                                                                                                                                                               1.7s 
 ✔ Container airflow-scheduler  Started                                                                                                                                                                               1.3s 
=========================================
Estado de contenedores
=========================================
NAME                IMAGE                   COMMAND                  SERVICE             CREATED              STATUS                                     PORTS
airflow-init        apache/airflow:2.10.3   "/usr/bin/dumb-init …"   airflow-init        About a minute ago   Up Less than a second                      8080/tcp
airflow-postgres    postgres:16             "docker-entrypoint.s…"   postgres            About a minute ago   Up About a minute (healthy)                5432/tcp
airflow-scheduler   apache/airflow:2.10.3   "/usr/bin/dumb-init …"   airflow-scheduler   1 second ago         Up Less than a second                      8080/tcp
airflow-webserver   apache/airflow:2.10.3   "/usr/bin/dumb-init …"   airflow-webserver   1 second ago         Up Less than a second (health: starting)   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp
=========================================
Validación local de UI
=========================================
curl: (56) Recv failure: Connection reset by peer
WARN: aún no responde, revisa logs

=========================================
Airflow LITE está corriendo
=========================================
URL: http://<EC2_PUBLIC_IP>:8080
Usuario: airflow
Password: airflow

Comandos útiles:
  docker-compose -f /home/ssm-user/airflow-docker/docker-compose.lite.yaml logs -f --tail=200 airflow-webserver
  docker-compose -f /home/ssm-user/airflow-docker/docker-compose.lite.yaml logs -f --tail=200 airflow-scheduler
  docker-compose -f /home/ssm-user/airflow-docker/docker-compose.lite.yaml logs -f --tail=200 postgres
  docker-compose -f /home/ssm-user/airflow-docker/docker-compose.lite.yaml down
  docker-compose -f /home/ssm-user/airflow-docker/docker-compose.lite.yaml down -v  # reset total
sh-4.2$ cd /home/ssm-user/airflow-docker
sh-4.2$ docker-compose -f docker-compose.lite.yaml down
[+] Running 5/5
 ✔ Container airflow-init          Removed                                                                                                                                                                            0.6s 
 ✔ Container airflow-scheduler     Removed                                                                                                                                                                            0.6s 
 ✔ Container airflow-webserver     Removed                                                                                                                                                                            0.6s 
 ✔ Container airflow-postgres      Removed                                                                                                                                                                            0.3s 
 ✔ Network airflow-docker_default  Removed                                                                                                                                                                            0.1s 
sh-4.2$ cd /home/ssm-user/airflow-docker
sh-4.2$ sudo chown -R 50000:0 logs dags plugins
sh-4.2$ sudo chmod -R 775 logs dags plugins
sh-4.2$ ls -ld logs dags plugins
drwxrwxr-x 2 50000 root  6 Feb 20 05:28 dags
drwxrwxr-x 3 50000 root 35 Feb 20 05:28 logs
drwxrwxr-x 2 50000 root  6 Feb 20 05:28 plugins
sh-4.2$ ls -la logs | head
total 0
drwxrwxr-x 3    50000 root      35 Feb 20 05:28 .
drwxr-xr-x 5 ssm-user ssm-user 104 Feb 20 05:28 ..
drwxrwxr-x 2    50000 root       6 Feb 20 05:28 dag_processor_manager
sh-4.2$ rm docker-compose.lite.yaml
sh-4.2$ pwd 
/home/ssm-user/airflow-docker
sh-4.2$ cat > docker-compose.lite.yaml <<'EOF'
> services:
>   postgres:
>     image: postgres:16
>     container_name: airflow-postgres
>     environment:
>       POSTGRES_USER: airflow
>       POSTGRES_PASSWORD: airflow
>       POSTGRES_DB: airflow
>     volumes:
>       - postgres-db-volume:/var/lib/postgresql/data
>     healthcheck:
>       test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
>       interval: 10s
>       timeout: 5s
>       retries: 10
>     restart: unless-stopped
> 
>   airflow-init:
>     image: apache/airflow:2.10.3
>     container_name: airflow-init
>     depends_on:
>       postgres:
>         condition: service_healthy
>     environment:
>       AIRFLOW_UID: "50000"
>       AIRFLOW__CORE__EXECUTOR: SequentialExecutor
>       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
>       AIRFLOW__CORE__LOAD_EXAMPLES: "false"
>       AIRFLOW__WEBSERVER__SECRET_KEY: "REEMPLAZA_POR_TOKEN_LARGO"
>       _AIRFLOW_WWW_USER_USERNAME: airflow
>       _AIRFLOW_WWW_USER_PASSWORD: airflow
>     volumes:
>       - ./dags:/opt/airflow/dags
>       - ./logs:/opt/airflow/logs
>       - ./plugins:/opt/airflow/plugins
>     command: >
>       bash -c "
>       airflow db migrate &&
>       airflow users create
>         --role Admin
>         --username airflow
>         --password airflow
>         --firstname Admin
>         --lastname User
>         --email admin@example.com
>       || true
>       "
>     restart: "no"
> 
>   airflow-webserver:
>     image: apache/airflow:2.10.3
>     container_name: airflow-webserver
>     depends_on:
>       postgres:
>         condition: service_healthy
>     environment:
>       AIRFLOW_UID: "50000"
>       AIRFLOW__CORE__EXECUTOR: SequentialExecutor
>       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
>       AIRFLOW__CORE__LOAD_EXAMPLES: "false"
>       AIRFLOW__WEBSERVER__SECRET_KEY: "REEMPLAZA_POR_TOKEN_LARGO"
>     volumes:
>       - ./dags:/opt/airflow/dags
>       - ./logs:/opt/airflow/logs
>       - ./plugins:/opt/airflow/plugins
>     ports:
>       - "8080:8080"
>     command: webserver
>     healthcheck:
>       test: ["CMD-SHELL", "curl -fsS http://localhost:8080/health || exit 1"]
>       interval: 20s
>       timeout: 5s
>       retries: 10
>     restart: unless-stopped
> 
>   airflow-scheduler:
>     image: apache/airflow:2.10.3
>     container_name: airflow-scheduler
>     depends_on:
>       postgres:
>         condition: service_healthy
>     environment:
>       AIRFLOW_UID: "50000"
>       AIRFLOW__CORE__EXECUTOR: SequentialExecutor
>       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
>       AIRFLOW__CORE__LOAD_EXAMPLES: "false"
>       AIRFLOW__WEBSERVER__SECRET_KEY: "REEMPLAZA_POR_TOKEN_LARGO"
>     volumes:
>       - ./dags:/opt/airflow/dags
>       - ./logs:/opt/airflow/logs
>       - ./plugins:/opt/airflow/plugins
>     command: scheduler
>     restart: unless-stopped
> 
> volumes:
>   postgres-db-volume:
> EOF
sh-4.2$ ls -ltr
total 8
-rwxr-xr-x 1 ssm-user ssm-user 3305 Feb 20 05:25 run_airflow_lite.sh
drwxrwxr-x 2    50000 root        6 Feb 20 05:28 plugins
drwxrwxr-x 3    50000 root       35 Feb 20 05:28 logs
drwxrwxr-x 2    50000 root        6 Feb 20 05:28 dags
-rw-r--r-- 1 ssm-user ssm-user 2831 Feb 20 05:38 docker-compose.lite.yaml
sh-4.2$ bash run_airflow_lite.sh 
=========================================
Pre-check: Docker y Docker Compose
=========================================
Using: docker-compose
Docker version 25.0.14, build 0bab007
Docker Compose version v2.29.7
=========================================
Validando docker-compose config
=========================================
OK: compose config
=========================================
Creando estructura local (dags/logs/plugins)
=========================================
chmod: changing permissions of ‘dags’: Operation not permitted
chmod: changing permissions of ‘logs’: Operation not permitted
chmod: changing permissions of ‘logs/dag_processor_manager’: Operation not permitted
chmod: changing permissions of ‘plugins’: Operation not permitted
sh-4.2$ cd /home/ssm-user/airflow-docker
sh-4.2$ 
sh-4.2$ docker-compose -f docker-compose.lite.yaml down
sh-4.2$ 
sh-4.2$ mkdir -p dags logs plugins logs/scheduler logs/dag_processor_manager
mkdir: cannot create directory ‘logs/scheduler’: Permission denied
sh-4.2$ sudo chown -R 50000:0 logs dags plugins
sh-4.2$ sudo chmod -R 775 logs dags plugins
sh-4.2$ ls -ld dags logs plugins
drwxrwxr-x 2 50000 root  6 Feb 20 05:28 dags
drwxrwxr-x 3 50000 root 35 Feb 20 05:28 logs
drwxrwxr-x 2 50000 root  6 Feb 20 05:28 plugins
sh-4.2$ cd /home/ssm-user/airflow-docker
sh-4.2$ 
sh-4.2$ docker-compose -f docker-compose.lite.yaml up airflow-init
[+] Running 3/2
 ✔ Network airflow-docker_default  Created                                                                                                                                                                            0.0s 
 ✔ Container airflow-postgres      Created                                                                                                                                                                            0.1s 
 ✔ Container airflow-init          Created                                                                                                                                                                            0.1s 
Attaching to airflow-init
airflow-init  | 
airflow-init  | /home/airflow/.local/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
airflow-init  | DB: postgresql+psycopg2://airflow:***@postgres/airflow
airflow-init  | Performing upgrade to the metadata database postgresql+psycopg2://airflow:***@postgres/airflow
airflow-init  | [2026-02-20T05:40:45.700+0000] {migration.py:207} INFO - Context impl PostgresqlImpl.
airflow-init  | [2026-02-20T05:40:45.701+0000] {migration.py:210} INFO - Will assume transactional DDL.
airflow-init  | [2026-02-20T05:40:45.703+0000] {migration.py:207} INFO - Context impl PostgresqlImpl.
airflow-init  | [2026-02-20T05:40:45.704+0000] {migration.py:210} INFO - Will assume transactional DDL.
airflow-init  | INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
airflow-init  | INFO  [alembic.runtime.migration] Will assume transactional DDL.
airflow-init  | INFO  [alembic.runtime.migration] Running stamp_revision  -> 5f2621c13b39
airflow-init  | Database migrating done!
airflow-init  | /home/airflow/.local/lib/python3.12/site-packages/airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
airflow-init  | 
airflow-init  | airflow users create command error: the following arguments are required: -e/--email, -f/--firstname, -l/--lastname, -r/--role, -u/--username, see help above.
airflow-init  | Usage: airflow users create [-h] -e EMAIL -f FIRSTNAME -l LASTNAME
airflow-init  |                             [-p PASSWORD] -r ROLE [--use-random-password] -u
airflow-init  |                             USERNAME [-v]
airflow-init  | 
airflow-init  | Create a user
airflow-init  | 
airflow-init  | Options:
airflow-init  |   -h, --help            show this help message and exit
airflow-init  |   -e, --email EMAIL     Email of the user
airflow-init  |   -f, --firstname FIRSTNAME
airflow-init  |                         First name of the user
airflow-init  |   -l, --lastname LASTNAME
airflow-init  |                         Last name of the user
airflow-init  |   -p, --password PASSWORD
airflow-init  |                         Password of the user, required to create a user without --use-random-password
airflow-init  |   -r, --role ROLE       Role of the user. Existing roles include Admin, User, Op, Viewer, and Public
airflow-init  |   --use-random-password
airflow-init  |                         Do not prompt for password. Use random string instead. Required to create a user without --password
airflow-init  |   -u, --username USERNAME
airflow-init  |                         Username of the user
airflow-init  |   -v, --verbose         Make logging output more verbose
airflow-init  | 
airflow-init  | examples:
airflow-init  | To create an user with "Admin" role and username equals to "admin", run:
airflow-init  | 
airflow-init  |     $ airflow users create \
airflow-init  |           --username admin \
airflow-init  |           --firstname FIRST_NAME \
airflow-init  |           --lastname LAST_NAME \
airflow-init  |           --role Admin \
airflow-init  |           --email admin@example.org
airflow-init  | /bin/bash: line 2: --role: command not found
airflow-init  | /bin/bash: line 3: --username: command not found
airflow-init  | /bin/bash: line 4: --password: command not found
airflow-init  | /bin/bash: line 5: --firstname: command not found
airflow-init  | /bin/bash: line 6: --lastname: command not found
airflow-init  | /bin/bash: line 7: --email: command not found
airflow-init  | /bin/bash: -c: line 8: syntax error near unexpected token `||'
airflow-init  | /bin/bash: -c: line 8: `|| true '
airflow-init exited with code 2
sh-4.2$ docker-compose -f docker-compose.lite.yaml up -d
[+] Running 4/4
 ✔ Container airflow-postgres   Healthy                                                                                                                                                                               0.6s 
 ✔ Container airflow-webserver  Started                                                                                                                                                                               1.8s 
 ✔ Container airflow-scheduler  Started                                                                                                                                                                               1.1s 
 ✔ Container airflow-init       Started                                                                                                                                                                               1.4s 
sh-4.2$ docker-compose -f docker-compose.lite.yaml ps
NAME                IMAGE                   COMMAND                  SERVICE             CREATED              STATUS                             PORTS
airflow-postgres    postgres:16             "docker-entrypoint.s…"   postgres            About a minute ago   Up About a minute (healthy)        5432/tcp
airflow-scheduler   apache/airflow:2.10.3   "/usr/bin/dumb-init …"   airflow-scheduler   35 seconds ago       Up 33 seconds                      8080/tcp
airflow-webserver   apache/airflow:2.10.3   "/usr/bin/dumb-init …"   airflow-webserver   35 seconds ago       Up 33 seconds (health: starting)   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp
sh-4.2$ curl -I http://localhost:8080 || true
HTTP/1.1 302 FOUND
Server: gunicorn
Date: Fri, 20 Feb 2026 05:41:58 GMT
Connection: close
Content-Type: text/html; charset=utf-8
Content-Length: 197
Location: /home
Cache-Control: no-store
X-Robots-Tag: noindex, nofollow
Set-Cookie: session=6535a1a8-dbef-4f7e-9c28-7efb04a7fc8b.KDIaLEOKqXqzVBlAWDOB-0lQTQU; Expires=Sun, 22 Mar 2026 05:41:58 GMT; HttpOnly; Path=/; SameSite=Lax

sh-4.2$ docker-compose -f docker-compose.lite.yaml logs --tail=120 airflow-webserver
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:46098 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:46702 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:46758 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:47000 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:47050 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:47648 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:47704 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:48113 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:48190 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:48244 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:48321 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:49499 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:49555 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:49932 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50002 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50052 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50107 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50379 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50449 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50499 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50554 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50590 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50660 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50710 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:50770 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:51046 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:51116 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:51166 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:51226 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:51485 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:51540 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:51787 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:51851 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:51895 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:51958 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:52212 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:52275 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:52463 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:52532 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:53040 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:53111 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:53334 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:53407 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:53961 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:54059 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:54322 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:54398 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:55022 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:55078 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:55310 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:55365 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:56196 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:56248 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:56508 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:56564 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:57087 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:57147 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:57187 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:57237 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:57560 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:57620 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:57660 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:57710 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:59106 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:59162 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:59316 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:59396 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:59452 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:59535 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:59594 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:59677 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:59733 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:59818 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:60639 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:60722 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:60778 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:60863 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:61167 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:61250 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:61306 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:61387 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:61696 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:61752 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:61954 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:61992 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:62660 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:62715 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:63882 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:63946 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:64582 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:64674 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:64940 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:65014 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:65117 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:65199 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:65385 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:65441 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:65874 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:65950 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:66003 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:66087 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:66686 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:66779 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:66918 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:66964 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:67735 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:67791 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:68043 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:68097 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:68532 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/azure/synapse/artifacts/models/_models_py3.py:68588 SyntaxWarning: invalid escape sequence '\d'
airflow-webserver  | /home/airflow/.local/lib/python3.12/site-packages/snowflake/sqlalchemy/base.py:1068 SAWarning: The GenericFunction 'flatten' is already registered and is going to be overridden.
airflow-webserver  | [2026-02-20 05:41:47 +0000] [21] [INFO] Listening at: http://0.0.0.0:8080 (21)
airflow-webserver  | [2026-02-20 05:41:47 +0000] [21] [INFO] Using worker: sync
airflow-webserver  | [2026-02-20 05:41:47 +0000] [39] [INFO] Booting worker with pid: 39
airflow-webserver  | [2026-02-20 05:41:47 +0000] [40] [INFO] Booting worker with pid: 40
airflow-webserver  | [2026-02-20 05:41:47 +0000] [41] [INFO] Booting worker with pid: 41
airflow-webserver  | [2026-02-20 05:41:47 +0000] [42] [INFO] Booting worker with pid: 42
airflow-webserver  | 127.0.0.1 - - [20/Feb/2026:05:41:52 +0000] "GET /health HTTP/1.1" 200 283 "-" "curl/7.88.1"
airflow-webserver  | 172.19.0.1 - - [20/Feb/2026:05:41:58 +0000] "HEAD / HTTP/1.1" 302 0 "-" "curl/8.3.0"
sh-4.2$ docker-compose -f docker-compose.lite.yaml ps
NAME                IMAGE                   COMMAND                  SERVICE             CREATED         STATUS                   PORTS
airflow-postgres    postgres:16             "docker-entrypoint.s…"   postgres            4 minutes ago   Up 4 minutes (healthy)   5432/tcp
airflow-scheduler   apache/airflow:2.10.3   "/usr/bin/dumb-init …"   airflow-scheduler   3 minutes ago   Up 3 minutes             8080/tcp
airflow-webserver   apache/airflow:2.10.3   "/usr/bin/dumb-init …"   airflow-webserver   3 minutes ago   Up 3 minutes (healthy)   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp
sh-4.2$ sudo ss -lntp | grep ':8080' || echo "NO LISTEN 8080"
LISTEN 0      128          0.0.0.0:8080       0.0.0.0:*    users:(("docker-proxy",pid=6068,fd=4))
LISTEN 0      128             [::]:8080          [::]:*    users:(("docker-proxy",pid=6075,fd=4))
sh-4.2$ curl -fsS -o /dev/null -w "HTTP=%{http_code}\n" http://localhost:8080/health || echo "FAIL health"
HTTP=200
sh-4.2$ curl -I http://localhost:8080 | head -n 5
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0   197    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
HTTP/1.1 302 FOUND
Server: gunicorn
Date: Fri, 20 Feb 2026 05:47:34 GMT
Connection: close
Content-Type: text/html; charset=utf-8
sh-4.2$ echo "=== ps ==="
=== ps ===
sh-4.2$ docker-compose -f docker-compose.lite.yaml ps
NAME                IMAGE                   COMMAND                  SERVICE             CREATED         STATUS                   PORTS
airflow-postgres    postgres:16             "docker-entrypoint.s…"   postgres            7 minutes ago   Up 7 minutes (healthy)   5432/tcp
airflow-scheduler   apache/airflow:2.10.3   "/usr/bin/dumb-init …"   airflow-scheduler   6 minutes ago   Up 6 minutes             8080/tcp
airflow-webserver   apache/airflow:2.10.3   "/usr/bin/dumb-init …"   airflow-webserver   6 minutes ago   Up 6 minutes (healthy)   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp
sh-4.2$ echo

sh-4.2$ echo "=== ports ==="
=== ports ===
sh-4.2$ sudo ss -lntp | grep ':8080' || true
LISTEN 0      128          0.0.0.0:8080       0.0.0.0:*    users:(("docker-proxy",pid=6068,fd=4))
LISTEN 0      128             [::]:8080          [::]:*    users:(("docker-proxy",pid=6075,fd=4))
sh-4.2$ echo

sh-4.2$ echo "=== health ==="
=== health ===
sh-4.2$ curl -fsS -o /dev/null -w "HTTP=%{http_code}\n" http://localhost:8080/health
HTTP=200
sh-4.2$ 
